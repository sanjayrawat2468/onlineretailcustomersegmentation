{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "PH-0ReGfmX4f",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "JcMwzZxoAimU",
        "8G2x9gOozGDZ",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjayrawat2468/onlineretailcustomersegmentation/blob/main/Online_Retail_Customer_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - **Online Retail Customer Segmentation**\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Unsupervised\n",
        "##### **Contribution**    - Sanjay Rawat(Individual)\n",
        "\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Customer segmentation is the process of separating customers into groups on the basis of their shared behavior or other attributes. The groups should be homogeneous within themselves and should also be heterogeneous to each other. The overall aim of this process is to identify high-value customer base i.e. customers that have the highest growth potential or are the most profitable.**\n",
        "\n",
        "### **Insights from customer segmentation are used to develop tailor-made marketing campaigns and for designing overall marketing strategy and planning.**"
      ],
      "metadata": {
        "id": "33k_BU8RDqyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **In this project, your task is to identify major customer segments on a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.**\n"
      ],
      "metadata": {
        "id": "-NYgo0NQD8R8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Description**"
      ],
      "metadata": {
        "id": "0MRQByZCEqNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **InvoiceNo:** Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\n",
        "### **StockCode:** Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.\n",
        "### **Description:** Product (item) name. Nominal.\n",
        "### **Quantity:** The quantities of each product (item) per transaction. Numeric.\n",
        "### **InvoiceDate:** Invice Date and time. Numeric, the day and time when each transaction was generated.\n",
        "### **UnitPrice:** Unit price. Numeric, Product price per unit in sterling.\n",
        "### **CustomerID:** Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.\n",
        "### **Country:** Country name. Nominal, the name of the country where each customer resides."
      ],
      "metadata": {
        "id": "fHNTpoA1Eurt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libararies**"
      ],
      "metadata": {
        "id": "EjBpZH6eFG2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Required Liberaries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "BMUyok4HFVts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting The Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vTwcG2sBL7h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Online Retail.xlsx - Online Retail.csv')"
      ],
      "metadata": {
        "id": "uSExOSvAMT78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Wrangling**"
      ],
      "metadata": {
        "id": "77wdewKoRf8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Ruytgqb_RnC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "YEEgw5qsRr2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "nuLkS6MzRzig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "lVLuZCzwR3QY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking For Null Values\n",
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "EvPFH-eOR-9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Here we have null values present in our dataset like in CustomerID and Description.we can drop those null values**"
      ],
      "metadata": {
        "id": "8kgyBhnSXkiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**"
      ],
      "metadata": {
        "id": "PYgiFLeRXyEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping Null Values\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "HZl43nnoX1tO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "XdhfVC9KX8yf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We will look for invoices with the letter c in the InvoiceNo column to see which means order is cancelled**"
      ],
      "metadata": {
        "id": "1Vx1ic3WfLKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing Datatype\n",
        "df['InvoiceNo'] = df['InvoiceNo'].astype('str')\n"
      ],
      "metadata": {
        "id": "Ehk1gpGGfKZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping The cancelled Orders\n",
        "df=df[~df['InvoiceNo'].str.contains('C')]"
      ],
      "metadata": {
        "id": "t44mIBZHfhmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "ha4WEswRqw-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Description_df=df['Description'].value_counts().reset_index()\n",
        "Description_df.rename(columns={'index': 'Description_Name'}, inplace=True)\n",
        "Description_df.rename(columns={'Description': 'Count'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "rlM6nUH1q5Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top Products Based On Selling**"
      ],
      "metadata": {
        "id": "wPMsHZ4Uvrw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 5 Description Name\n",
        "Description_df.head()"
      ],
      "metadata": {
        "id": "3U4RbWRjrAFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Top 5 Product Name\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Top 5 Product Name')\n",
        "sns.barplot(x='Count',y='Description_Name',data=Description_df[:5]);"
      ],
      "metadata": {
        "id": "m-SsHO7brHzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bottom 5 Product Based On Selling**"
      ],
      "metadata": {
        "id": "rmXlpJdev6do"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bottom 5 Description Name\n",
        "Description_df.tail()"
      ],
      "metadata": {
        "id": "uHEczdVMwBa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Country Name**\n",
        "\n"
      ],
      "metadata": {
        "id": "xtPp7UNbxyyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "country_df=df['Country'].value_counts().reset_index()\n",
        "country_df.rename(columns={'index': 'Country_Name'}, inplace=True)\n",
        "country_df.rename(columns={'Country': 'Count'}, inplace=True)"
      ],
      "metadata": {
        "id": "l7zmGyjzx6Pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Top 5 Country Name Based On Customer Count**"
      ],
      "metadata": {
        "id": "qhrvNoE-x9le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 5 Country Name Based On Customer\n",
        "country_df.head()\n"
      ],
      "metadata": {
        "id": "Nx2QtmMSyGkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Top 5 Country based on the Most Numbers Of Customers')\n",
        "sns.barplot(x='Count',y='Country_Name',data=country_df[:5]);"
      ],
      "metadata": {
        "id": "NPeqBjiyyjlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this graph we can see that most of the customers are from United Kingdom that make sense aas company is from UK bases after that we have Germany ,France ,EIRE and Spain**"
      ],
      "metadata": {
        "id": "7evPpd6tz73j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bottom 5 Country Name Based On Customers**"
      ],
      "metadata": {
        "id": "uOqndAYIyTz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bottom 5 Country Name\n",
        "country_df.tail()"
      ],
      "metadata": {
        "id": "BJ-zlh-wyYmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Bottom 5 Countries based on Customers')\n",
        "sns.barplot(x='Count',y='Country_Name',data=country_df[-5:]);"
      ],
      "metadata": {
        "id": "46kJumaNy9no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From this graph we can see that least number of customers from Lithuania,Brazil, Czech Republic ,Bahrain and Saudi Arabia**"
      ],
      "metadata": {
        "id": "03JJMD-NG6AP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Distribution of Quantity**\n",
        "\n"
      ],
      "metadata": {
        "id": "HD29ip8fGnXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Distribution Of Quantity\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.title('distribution of Quantity')\n",
        "sns.distplot(df['Quantity']);"
      ],
      "metadata": {
        "id": "Yu-9DlwUGo8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above graph we can clearly see that its a Positively skewed (or right-skewed) distribution.**"
      ],
      "metadata": {
        "id": "i9STApasHAH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming Skewed Distribution Using log Transformation\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.title('log distribution of Quantity')\n",
        "sns.distplot(np.log(df['Quantity']));"
      ],
      "metadata": {
        "id": "jN0mtHcwHI8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "TsuS0py4p4-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting InvoiceDate Columns Into date time format\n",
        "from datetime import datetime\n",
        "\n",
        "df[\"InvoiceDate\"] = pd.to_datetime(df[\"InvoiceDate\"])"
      ],
      "metadata": {
        "id": "Uv202Km6p-Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new features from Invoicedate\n",
        "df['Month']=df['InvoiceDate'].dt.month_name()\n",
        "df['Day']=df['InvoiceDate'].dt.day_name()\n",
        "df['Hour']=df['InvoiceDate'].dt.hour"
      ],
      "metadata": {
        "id": "bhdrcIYscj62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transaction Made Per Month**"
      ],
      "metadata": {
        "id": "vkP53u9gKUb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a New Column\n",
        "month_df=df['Month'].value_counts().reset_index()\n",
        "month_df.rename(columns={'index': 'Month_Name'}, inplace=True)\n",
        "month_df.rename(columns={'Month': 'Count'}, inplace=True)\n",
        "month_df"
      ],
      "metadata": {
        "id": "c6bMwqNMK7Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting for monthwise transactions\n",
        "plt.figure(figsize=(13,8))\n",
        "ax = sns.barplot(x='Month_Name', y='Count', data=month_df)\n",
        "\n",
        "# Add the percentage values in the middle of each bar\n",
        "for i, v in enumerate(month_df['Count']):\n",
        "    ax.text(i, v, str(round(v / month_df['Count'].sum() * 100, 2)) + '%', color='black', ha='center', fontweight='bold')\n",
        "    \n",
        "plt.title('Month-Wise Transaction')\n",
        "sns.barplot(x='Month_Name',y='Count',data=month_df);"
      ],
      "metadata": {
        "id": "ZDmNXiOBc8FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Most numbers of customers made purchases in the month of November, October and December this could be due to festive season in end of the year as well new year to celebrate so we have highest numbers of transaction in november, october, december.**\n",
        "\n",
        "**Least numbers of purchasing are in the month of April and February.**"
      ],
      "metadata": {
        "id": "VO22mcG1vr0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating another dataframe \n",
        "day_df=df['Day'].value_counts().reset_index()\n",
        "day_df.rename(columns={'index': 'Day_Name'}, inplace=True)\n",
        "day_df.rename(columns={'Day': 'Count'}, inplace=True)\n",
        "day_df"
      ],
      "metadata": {
        "id": "yNOZ8qMnbgVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the graph daywise transactions\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Day-wise transaction')\n",
        "sns.barplot(x='Day_Name',y='Count',data=day_df);"
      ],
      "metadata": {
        "id": "K0IBZtMYbnbi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From above graph we can see the maximum number of transaction are for thursday but we can also see there are no transaction on saturday may be lack of data or missing data.**\n",
        "\n",
        "**Most of the transaction took place on Thursday ,Wednesday and Tuesday.**"
      ],
      "metadata": {
        "id": "PDbnGbdDb9lK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating another dataframe for hour\n",
        "hour_df=df['Hour'].value_counts().reset_index()\n",
        "hour_df.rename(columns={'index': 'Hours'}, inplace=True)\n",
        "hour_df.rename(columns={'Hour': 'Count'}, inplace=True)\n",
        "hour_df"
      ],
      "metadata": {
        "id": "aeZJXzQxcV8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the graph for hourly transactions\n",
        "plt.figure(figsize=(13,8))\n",
        "plt.title('Hourly transactions')\n",
        "sns.barplot(x='Hours',y='Count',data=hour_df);"
      ],
      "metadata": {
        "id": "iVUEK6adcfZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**By seeing the above graph we can say that most numbers of transactions done between 12pm clock to 3pm.**"
      ],
      "metadata": {
        "id": "YcLoDKZcc0EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividing hours into different time periods like morning, afternoon and evening\n",
        "def time_type(time):\n",
        "  if(time>=6 and time<=11):\n",
        "    return 'Morning'\n",
        "  elif(time>=12 and time<=17):\n",
        "    return 'Afternoon'\n",
        "  else:\n",
        "    return 'Evening'"
      ],
      "metadata": {
        "id": "xgeZYFr-fCRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying function on hour column\n",
        "df['Time_type']=df['Hour'].apply(time_type)"
      ],
      "metadata": {
        "id": "m9JCW2KRfOnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Time_type wise transaction')\n",
        "sns.countplot(x='Time_type',data=df);"
      ],
      "metadata": {
        "id": "bs-wO9u4fSfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From the above graph we can see that afternoon is the bussiest time slot where most of the transactions tooks place.**"
      ],
      "metadata": {
        "id": "vw58j26Bo2LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Top Customers**"
      ],
      "metadata": {
        "id": "CzG-YOT7oEIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a dataframe of top customers by number of transactions\n",
        "top_customers = pd.DataFrame(df['CustomerID'].value_counts().sort_values(ascending = False).reset_index())"
      ],
      "metadata": {
        "id": "krm6ZpuTn3Gn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_customers.rename(columns = {'index':'CustomerID','CustomerID':'count'},inplace = True)\n",
        "\n",
        "# Displaying the top 5 customers\n",
        "top_customers.head(5)"
      ],
      "metadata": {
        "id": "aRXqkchdn-wg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,7))\n",
        "sns.barplot(x = 'CustomerID',y = 'count',data = top_customers[:5])\n",
        "plt.xlabel('Customer ID', fontsize = 12)\n",
        "plt.ylabel('Frequency', fontsize = 12)\n",
        "plt.title(\"Top 5 Customer's ID\", fontsize = 16)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R3L6TxaeoTvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The chart provides insight into the customers who make the most purchases from the business and helps identify potential loyal customers or areas for improvement in customer retention.**"
      ],
      "metadata": {
        "id": "nNm3qkZkou-S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Top Selling products**"
      ],
      "metadata": {
        "id": "tEbSQm6BpCiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group the data by product name and calculate the sum of the quantity sold for each product\n",
        "product_group = df.groupby('Description').sum()['Quantity']"
      ],
      "metadata": {
        "id": "9Fw9M9MxpBlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the data in descending order\n",
        "product_group = product_group.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "Zg9A9RM9pNG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the top 10 items\n",
        "top_10_selling_products = product_group.index[:10]"
      ],
      "metadata": {
        "id": "J2dBC9EvpTuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new dataframe to store the top 10 selling products\n",
        "top_10_products_df = pd.DataFrame({'Product': top_10_selling_products, 'Quantity Sold': product_group.values[:10]})\n",
        "top_10_products_df"
      ],
      "metadata": {
        "id": "ZUBbJhb9pZFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(top_10_products_df['Product'], top_10_products_df['Quantity Sold'])\n",
        "\n",
        "# Set the title and axis labels\n",
        "plt.title('Top 10 Selling Products', size=15, fontweight='bold')\n",
        "plt.xlabel('Product', size=15)\n",
        "plt.ylabel('Quantity Sold', size=15)\n",
        "\n",
        "# Rotate the x-axis labels\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d9QVJBRgply1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A bar chart is a good choice for showing the quantity of each product sold as it allows for easy comparison between the different products. It is also effective in highlighting the top 10 selling products.**\n",
        "\n",
        "\n",
        "**This chart shows the quantity of each of the top 10 selling products, providing insight into the most popular items. It also allows for comparison between the different products and their respective quantities sold.**"
      ],
      "metadata": {
        "id": "PfbylW8bqU55"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RFM Analysis**\n",
        "\n",
        "**RFM analysis is a marketing technique that segments customers based on their recency (time since last purchase), frequency (number of purchases), and monetary value (amount spent) of their transactions. This helps businesses understand their customers better and make data-driven decisions about marketing and customer engagement.**\n",
        "\n",
        "**Three dimensions of RFM are -**\n",
        "\n",
        "**Recency -** In order to find the recency value of each customer, we need to determine the last invoice date as the current date and subtract the last purchasing date of each customer from this date.\n",
        "\n",
        "**Frequency -**In order to find the frequency value of each customer, we need to determine how many times the customers make purchases.\n",
        "\n",
        "**Monetary -** In order to find the monetary value of each customer, we need to determine how much do the customers spend on purchases."
      ],
      "metadata": {
        "id": "cjAEGAHs2uoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime as dt\n",
        "# Recency = Latest Date - Last Inovice Data, Frequency = count of invoice no. of transaction(s), Monetary = Sum of Total \n",
        "# Amount for each customer\n",
        "\n",
        "# Get the latest value of the 'InvoiceDate' column\n",
        "last_date = df['InvoiceDate'].max()\n",
        "last_date"
      ],
      "metadata": {
        "id": "Tlq3eMwjAX4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Latest date 2011-12-10 as last invoice date was 2011-12-09\n",
        "Latest_Date = dt.datetime(2011,12,10)"
      ],
      "metadata": {
        "id": "1ikCbEG2A_Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new feature TotalAmount from product of Quantity and Unitprice\n",
        "df['TotalAmount']=df['Quantity']*df['UnitPrice']\n",
        "\n",
        "# Create RFM Modelling scores for each customer\n",
        "rfm_df = df.groupby('CustomerID').agg({'InvoiceDate': lambda x: (Latest_Date - x.max()).days, 'InvoiceNo': lambda x: len(x), 'TotalAmount': lambda x: x.sum()})\n"
      ],
      "metadata": {
        "id": "_oJOnZpABGxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The RFM dataframe combines recency, frequency, and monetary value information for each customer to provide a comprehensive overview of their behavior and spending habits.**"
      ],
      "metadata": {
        "id": "1ni9o-NGCHJp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert Invoice Date into type int\n",
        "rfm_df['InvoiceDate'] = rfm_df['InvoiceDate'].astype(int)\n",
        "\n",
        "#Rename column names to Recency, Frequency and Monetary\n",
        "rfm_df.rename(columns={'InvoiceDate': 'Recency', \n",
        "                         'InvoiceNo': 'Frequency', \n",
        "                         'TotalAmount': 'Monetary'}, inplace=True)\n",
        "\n",
        "rfm_df.reset_index().head()"
      ],
      "metadata": {
        "id": "D-7fgz3wB5O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recency Ditribution Over Plot**"
      ],
      "metadata": {
        "id": "ow7r4WrYlr4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recency distribution plot\n",
        "import seaborn as sns\n",
        "x = rfm_df['Recency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x);"
      ],
      "metadata": {
        "id": "9VdaPqlolh0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequency Ditribution Over Plot**"
      ],
      "metadata": {
        "id": "iw3XFI7Tl07C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = rfm_df['Frequency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x,);"
      ],
      "metadata": {
        "id": "fisRhUIal9B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Monateray Distribution Over Plot**"
      ],
      "metadata": {
        "id": "_jUGH7EWmLl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Monateray distribution plot\n",
        "x = rfm_df['Monetary']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(x)"
      ],
      "metadata": {
        "id": "a_PaIhyLmUdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**From all the above graphs of Recency,Frequency and Monetary we can say that all are positively skewed distribution.for that we can use quantile method -**\n",
        "\n"
      ],
      "metadata": {
        "id": "HkARMrmmmct2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantile Method**"
      ],
      "metadata": {
        "id": "EtMX1ZRjmsVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into quantiles\n",
        "quantiles = rfm_df.quantile(q=[0.25,0.5,0.75])\n",
        "quantiles = quantiles.to_dict()\n",
        "quantiles"
      ],
      "metadata": {
        "id": "vO24h2Yzmrk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Functions to create R, F and M segments according to quantiles for recency low score is important and for frequency and monetory maximum is important.\n",
        "def RScoring(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 1\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 2\n",
        "    elif x <= d[p][0.75]: \n",
        "        return 3\n",
        "    else:\n",
        "        return 4\n",
        "    \n",
        "def FnMScoring(x,p,d):\n",
        "    if x <= d[p][0.25]:\n",
        "        return 4\n",
        "    elif x <= d[p][0.50]:\n",
        "        return 3\n",
        "    elif x <= d[p][0.75]: \n",
        "        return 2\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "7R8lImbjnCUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rfm_df['R'] = rfm_df['Recency'].apply(RScoring, args=('Recency',quantiles,))\n",
        "rfm_df['F'] = rfm_df['Frequency'].apply(FnMScoring, args=('Frequency',quantiles,))\n",
        "rfm_df['M'] = rfm_df['Monetary'].apply(FnMScoring, args=('Monetary',quantiles,))\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "fumzqho-nH4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling negative and zero values so as to handle infinite numbers during log transformation\n",
        "def handle_neg_n_zero(num):\n",
        "    if num <= 0:\n",
        "        return 1\n",
        "    else:\n",
        "        return num\n",
        "#Applying handle_neg_n_zero function to Recency and Monetary columns \n",
        "rfm_df['Recency'] = [handle_neg_n_zero(x) for x in rfm_df.Recency]\n",
        "rfm_df['Monetary'] = [handle_neg_n_zero(x) for x in rfm_df.Monetary]\n",
        "\n",
        "#Performing Log transformation to bring data into normal or near normal distribution\n",
        "Log_Tfd_Data = rfm_df[['Recency', 'Frequency', 'Monetary']].apply(np.log, axis = 1).round(3)\n"
      ],
      "metadata": {
        "id": "m-NJhReY96Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution after data normalization for Recency\n",
        "Recency_Plot = Log_Tfd_Data['Recency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(Recency_Plot);"
      ],
      "metadata": {
        "id": "S1LcNwkZ9zZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution after data normalization for Frequency\n",
        "Frequency_Plot = Log_Tfd_Data.query('Frequency < 1000')['Frequency']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(Frequency_Plot);"
      ],
      "metadata": {
        "id": "sQ5rWf2P-u8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data distribution after data normalization for Monetary\n",
        "Monetary_Plot = Log_Tfd_Data.query('Monetary < 10000')['Monetary']\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.distplot(Monetary_Plot);"
      ],
      "metadata": {
        "id": "M6asFwBa-2B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see from the above plots, skewness has been removed from the data.**\n",
        "\n"
      ],
      "metadata": {
        "id": "s5asPxBs-8_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the concatenated score of RFM\n",
        "rfm_df['RFMGroup'] = rfm_df.R.map(str) + rfm_df.F.map(str) + rfm_df.M.map(str)"
      ],
      "metadata": {
        "id": "FsdEcUM2nWW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate and Add RFMScore value column showing total sum of RFMGroup values\n",
        "rfm_df['RFMScore'] = rfm_df[['R', 'F', 'M']].sum(axis = 1)\n",
        "rfm_df.head()"
      ],
      "metadata": {
        "id": "Zt5s3_Kzndm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the dataframe by MonetaryValue in descending order and reset the index\n",
        "rfm_df2 = rfm_df[rfm_df['RFMGroup'] == '444'].sort_values('Monetary', ascending=False)\n",
        "rfm_df2.head(10)"
      ],
      "metadata": {
        "id": "5K4cIjAgu7Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorising customer or making customer segmentation based on RFM Score\n",
        "print(\"Best Customers: \",len(rfm_df[rfm_df['RFMGroup']=='444']))\n",
        "print('Loyal Customers: ',len(rfm_df[rfm_df['F']==4]))\n",
        "print(\"Big Spenders: \",len(rfm_df[rfm_df['M']==4]))\n",
        "print('Almost Lost: ', len(rfm_df[rfm_df['RFMGroup']=='244']))\n",
        "print('Lost Customers: ',len(rfm_df[rfm_df['RFMGroup']=='144']))\n",
        "print('Lost Cheap Customers: ',len(rfm_df[rfm_df['RFMGroup']=='111']))"
      ],
      "metadata": {
        "id": "hBO1xaZjpmZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**With the segmentation of our customers based on their RFM scores, we can now tailor our marketing strategies to each segment effectively.**\n",
        "\n",
        "**For example, our \"Best Customers\" or \"Champions\" can be rewarded for their loyalty. These customers can also serve as early adopters for new products, so we can suggest them to participate in a \"Refer a Friend\" program.**\n",
        "\n",
        "**For customers who are \"At Risk\", we can send them personalized emails to encourage them to make a purchase. This can help to retain them as customers and keep them engaged with our brand.**"
      ],
      "metadata": {
        "id": "ZaTpR3Ak75lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping the RFMScore and its components columns from the dataframe\n",
        "rfm_data = rfm_df.drop(['R','F','M','RFMScore','RFMGroup'], axis=1)"
      ],
      "metadata": {
        "id": "GY95RUyn8S5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation between the variables\n",
        "correlation = rfm_data.corr()\n",
        "\n",
        "# Display the correlation matrix\n",
        "correlation"
      ],
      "metadata": {
        "id": "dCB4q7Qln0Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the heatmap of the feature correlations in the dataframe\n",
        "sns.heatmap(rfm_data.corr(), annot=True, cmap='Reds');"
      ],
      "metadata": {
        "id": "T6X_H2oFn8T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The insight is that there is a negative correlation between recency and both frequency and monetary, indicating that customers who have recently made a purchase are less likely to make another purchase. There is also a positive but weak correlation between frequency and monetary.**\n",
        "\n",
        "**The insights can help create a positive business impact by helping businesses better understand customer behaviour and tailor their sales and promotions accordingly.**"
      ],
      "metadata": {
        "id": "Wn3fMoKg9dj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot the distribution of Recency, Frequency, and Monetary**"
      ],
      "metadata": {
        "id": "gXP1I1JqIPw5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A scatter matrix is a visual representation of the relationships between multiple variables or features in a dataset. It can help identify patterns, trends, and correlations between the variables. It is a useful tool for exploratory data analysis and can help provide insight into the data.**\n",
        "\n"
      ],
      "metadata": {
        "id": "-Spo3VZ1IY5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the distribution of features in the dataset using Seaborn.\n",
        "sns.pairplot(rfm_data, diag_kind='kde');"
      ],
      "metadata": {
        "id": "Cra5Z6NXIa2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The pairplot with kde diagonal plots was chosen as it is an effective way to visualize the distribution and pairwise relationships between multiple features in a dataset. It allows us to quickly identify any correlations or patterns between variables, making it an excellent choice for visualizing the distribution of features in the dataset.**\n",
        "\n",
        "**We can observe that the distributions of the three variables are skewed. This suggests that normalization is necessary to make the data features normally distributed, as most clustering algorithms require them to be normally distributed.**"
      ],
      "metadata": {
        "id": "FmynboWDIqxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The skew() method is used to measure the asymmetry of the data around the mean. \n",
        "rfm_data.skew()"
      ],
      "metadata": {
        "id": "cBKoT-fDIxib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot the distribution of Recency, Frequency, and Monetary after Data Normalization**"
      ],
      "metadata": {
        "id": "swLKSnmCsVtY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(data = Log_Tfd_Data, diag_kind='kde');"
      ],
      "metadata": {
        "id": "w6C-6e56qqzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The distribution of the Frequency and Monetary features have improved and appear to be more normal, but the distribution of the Recency feature has only improved to some extent and is still not as well-normalized as the other two features.**\n",
        "\n"
      ],
      "metadata": {
        "id": "0KClraM8tITu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Log_Tfd_Data.head()"
      ],
      "metadata": {
        "id": "1019PLxbreiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Heatmap**"
      ],
      "metadata": {
        "id": "STUxPYR8tQst"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features correlation after log transformation or data normalization\n",
        "sns.heatmap(Log_Tfd_Data.corr(),annot=True, cmap='Reds');"
      ],
      "metadata": {
        "id": "eidXsCOgtlgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The correlation between Monetary and Frequency is now stronger.**"
      ],
      "metadata": {
        "id": "1M8Tl4m2wDGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Scaling**"
      ],
      "metadata": {
        "id": "bUCAkxCv25hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the normalized data to a variable \"X\"\n",
        "X = Log_Tfd_Data"
      ],
      "metadata": {
        "id": "KtawnY0f29Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the features to use for K-means\n",
        "features = ['Recency', 'Frequency', 'Monetary']\n",
        "\n",
        "# Standardize the feature values\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(Log_Tfd_Data[features].values)"
      ],
      "metadata": {
        "id": "HSwqxseD3IPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I used Standardization to transform my features in order to ensure that they had a similar scale and distribution. This was important because some machine learning algorithms are sensitive to the scale and distribution of features, and Standardization helps to ensure unbiased results.**"
      ],
      "metadata": {
        "id": "JzKu35WC5nQh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ML Model Implementation**"
      ],
      "metadata": {
        "id": "5VdsVqiV5uvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-means Implementation**"
      ],
      "metadata": {
        "id": "MJBYg5wY5xc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**K-means is a clustering algorithm that groups data points into K clusters. Choosing the right number of clusters can be challenging. The Silhouette Coefficient can be used to evaluate the quality of the clusters by measuring the similarity of each data point to its assigned cluster. A high Silhouette Score indicates a good quality cluster. To ensure a high-quality solution, k-means++ should be used for initialization.**"
      ],
      "metadata": {
        "id": "1ARwUx8654jG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means with silhouette_score**"
      ],
      "metadata": {
        "id": "qSD608029Fw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn import preprocessing\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4hLlH38G52cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "silhouette_scores = []\n",
        "\n",
        "# Loop over different values of K\n",
        "for n_clusters in range(2, 16):\n",
        "    # Initialize the KMeans model with the number of clusters\n",
        "    kmeans = KMeans(n_clusters=n_clusters, init='k-means++')\n",
        "    \n",
        "    # Fit the KMeans model to the data\n",
        "    kmeans.fit(X)\n",
        "    \n",
        "    # Predict the cluster labels for each data point\n",
        "    labels = kmeans.labels_\n",
        "    \n",
        "    # Calculate the silhouette score for this solution\n",
        "    silhouette = silhouette_score(X, labels)\n",
        "    \n",
        "    # Append the silhouette score to the array\n",
        "    silhouette_scores.append(silhouette)\n",
        "    \n",
        "    # Print the silhouette score for this solution\n",
        "    print(f\"Silhouette score for {n_clusters} clusters: {silhouette:.3f}\")\n",
        "    \n",
        "# Plot the silhouette scores\n",
        "plt.plot(range(2, 16), silhouette_scores, '-o', color='red', markersize=10, linewidth=2)\n",
        "plt.xlabel('Number of clusters (K)', fontsize=14)\n",
        "plt.ylabel('Silhouette score', fontsize=14)\n",
        "plt.title('Silhouette score for different values of K', fontsize=16)\n",
        "plt.xticks(range(2, 16), fontsize = 12)\n",
        "plt.yticks(fontsize=12)\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UhbgF0_36i32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The silhouette score plot is commonly used to evaluate the quality of clustering.**\n",
        "\n",
        "**The plot suggests that 2 clusters are optimal for the dataset.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ahSoZVJ368NT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate a KMeans object with 2 clusters\n",
        "kmeans = KMeans(n_clusters=2)\n",
        "\n",
        "# Fit the input data X to the KMeans model\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Predict the cluster labels for the input data X using the trained KMeans model\n",
        "y_kmeans = kmeans.predict(X)"
      ],
      "metadata": {
        "id": "_AzS8RCl8Okq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of customer segmentation based On RFM features. \n",
        "# Set the figure size and title for the scatter plot\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.title('Customer Segmentation Based on RFM Features')\n",
        "\n",
        "# Plot the scatter plot using the first two features of the input data X and the predicted cluster labels y_kmeans\n",
        "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='RdYlBu')\n",
        "\n",
        "# Get the cluster centers from the trained KMeans model and plot them as yellow circles with transparency\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='yellow', s=200, alpha=0.5, edgecolor='black')\n",
        "\n",
        "# Set the x-axis and y-axis labels\n",
        "plt.xlabel('Recency')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Add a color bar to the plot to show the correspondence between the colors and the cluster labels\n",
        "color_bar = plt.colorbar()\n",
        "color_bar.set_ticks(np.unique(y_kmeans))\n",
        "color_bar.set_ticklabels(['Cluster {}'.format(i) for i in np.unique(y_kmeans)])\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "     \n"
      ],
      "metadata": {
        "id": "DXZ5iZA98U5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The scatter plot is commonly used to visualize the distribution of data points in a 2D space. In this case, the scatter plot is used to visualize customer segmentation based on RFM (Recency, Frequency, Monetary) features.**\n",
        "\n",
        "**The scatter plot reveals distinct clusters of customers based on their RFM features. This allows businesses to identify groups of customers with similar behavior and tailor their marketing strategies accordingly. The cluster centers (yellow circles) also provide a visual representation of the typical RFM profile of each customer segment**\n",
        "\n",
        "**By enabling businesses to identify and target specific customer segments with personalized marketing strategies and product recommendations. This can lead to improved customer experiences, increased customer loyalty, and ultimately, positive business impact.**"
      ],
      "metadata": {
        "id": "h7U04aOk8bSE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **K-Means with Elbow method**"
      ],
      "metadata": {
        "id": "qmmTkpEs6Ko7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The elbow method is used to find the optimal number of clusters for KMeans clustering. It involves plotting the within-cluster sum of squares (WCSS) against the number of clusters. The elbow point on the plot corresponds to the optimal number of clusters that balances the trade-off between model complexity and data structure.**"
      ],
      "metadata": {
        "id": "KYL9qZhc9Nj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to store the WCSS values for different number of clusters\n",
        "wcss = []  \n",
        "\n",
        "for i in range(1, 11):\n",
        "    # Create a KMeans instance for each number of clusters\n",
        "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
        "    # Fit the KMeans model to the input data X \n",
        "    kmeans.fit(X)\n",
        "    # Append the WCSS value to the list for the current number of clusters \n",
        "    wcss.append(kmeans.inertia_)  \n",
        "\n",
        "# Plot the WCSS values against the number of clusters\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(range(1, 11), wcss, marker='o', linestyle='--')\n",
        "plt.title('The Elbow Method')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('WCSS')\n",
        "plt.xticks(np.arange(1, 11, 1))\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hkGkF5uS9JQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Elbow Method plot is commonly used to identify the optimal number of clusters in a K-means clustering algorithm.**\n"
      ],
      "metadata": {
        "id": "HQ96rg_--3BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the KMeans model with 2 clusters and initialize the centroids using the 'k-means++' method\n",
        "KMean_clust = KMeans(n_clusters= 2, init= 'k-means++', max_iter= 1000)\n",
        "\n",
        "# Fit the KMeans model to the data in the X variable\n",
        "KMean_clust.fit(X)\n",
        "\n",
        "# Add a new column to the rfm_df dataframe to store the cluster labels for each observation\n",
        "rfm_df['Cluster'] = KMean_clust.labels_\n",
        "\n",
        "# Display the first 10 rows of the rfm_df dataframe with the new 'Cluster' column\n",
        "rfm_df.head(10)"
      ],
      "metadata": {
        "id": "1QnEH-nf_A78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Agglomerative Hierarchial Clustering**"
      ],
      "metadata": {
        "id": "-LhvcitD_GHD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Agglomerative Hierarchical Clustering is a clustering algorithm that starts with each data point in its own cluster, and then merges the two closest clusters until only one remains, producing a tree-like structure. Different distance metrics and linkage criteria can be used to determine proximity between clusters. It is a popular and effective method for exploratory data analysis.**\n",
        "\n"
      ],
      "metadata": {
        "id": "vNiAQhWC_KmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "# Create an instance of AgglomerativeClustering with 2 clusters, euclidean affinity, and ward linkage\n",
        "model = AgglomerativeClustering(n_clusters=2, affinity='euclidean', linkage='ward')\n",
        "\n",
        "# Fit the input data X to the model\n",
        "model.fit(X)"
      ],
      "metadata": {
        "id": "foQh4VaE_QFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from scipy.spatial.distance import pdist\n",
        "\n",
        "# Set the figure size and title for the dendrogram plot\n",
        "plt.figure(figsize=(15, 12))\n",
        "plt.title('Agglomerative Hierarchical Clustering Dendogram')\n",
        "\n",
        "# Set the x and y-axis labels for the dendrogram plot\n",
        "plt.xlabel('Sample index')\n",
        "plt.ylabel('Distance')\n",
        "\n",
        "# Create a linkage matrix using the input data X and the ward linkage method\n",
        "Z = linkage(X, 'ward')\n",
        "\n",
        "# Plot the dendrogram with specified parameters\n",
        "dendrogram(Z, leaf_rotation=90.0, p=25, color_threshold=80, leaf_font_size=10, truncate_mode='level')\n",
        "\n",
        "# Ensure tight layout of the plot\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "oUtFF0Ug_YYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I picked a dendrogram plot because it is a common way to visualize the results of hierarchical clustering, which is the clustering method used in this case.**\n",
        "\n",
        "**The dendrogram plot shows how the data points are clustered based on their distance to each other. It helps identify the optimal number of clusters and the hierarchical structure of the clusters.**\n",
        "\n",
        "**The insights gained from the dendrogram plot can help identify the optimal number of clusters and determine which observations or clusters are most similar to each other. This information can be used to create more targeted marketing or sales strategies and improve overall business performance.**\n"
      ],
      "metadata": {
        "id": "vVkPkSeAAFNm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DBSCAN (Density-Based Spatial Clustering of Applications with Noise)**"
      ],
      "metadata": {
        "id": "HM-gi3ZZAU3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DBSCAN is a clustering algorithm that groups together data points that are close to each other and are part of a dense region of the dataset. It is useful for handling non-linearly separable data and can handle noise and outliers.**"
      ],
      "metadata": {
        "id": "up4nBEgpAZPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Create and fit the DBSCAN model\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=15)\n",
        "dbscan.fit(X)\n",
        "\n",
        "# Plot the results\n",
        "plt.scatter(X[:,0], X[:,1], c=dbscan.labels_, cmap='rainbow')\n",
        "plt.title('DBSCAN Clustering')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U-5PMHiXAd3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The chart used is a scatter plot, which is a suitable choice for visualizing the clustering results of DBSCAN. The x and y axes represent the two features of the dataset, and the points are colored based on their assigned cluster labels.**\n",
        "\n",
        "**The insights gained from the chart include identifying the clusters formed by the DBSCAN algorithm and their density. The points that are closer to each other are assigned to the same cluster, and the outliers or noise points are labeled as -1. By observing the distribution of the points and the density of the clusters, we can understand the structure and characteristics of the data, and potentially find any patterns or anomalies.**\n",
        "\n",
        "\n",
        "**The gained insights can help in creating a positive business impact by identifying groups of similar data points, which can aid in targeting specific segments of customers or optimizing operational processes.**\n"
      ],
      "metadata": {
        "id": "dTrXbrkgAiLM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary Table**"
      ],
      "metadata": {
        "id": "0Swv9UCRAtLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Initialize the table with specified column names\n",
        "myTable = PrettyTable(['SL No.', \"Model_Name\", 'Data', \"Optimal_Number_of_cluster\"])\n",
        "\n",
        "# Add rows to the table\n",
        "myTable.add_row(['1', \"K-Means with silhouette_score\", \"RFM\", \"2\"])\n",
        "myTable.add_row(['2', \"K-Means with Elbow method\", \"RFM\", \"2\"])\n",
        "myTable.add_row(['3', \"Hierarchical clustering\", \"RFM\", \"2\"])\n",
        "myTable.add_row(['4',\"DBSCAN \", \"RFM\", \"3\"])\n",
        "\n",
        "# Print the table\n",
        "print(myTable)"
      ],
      "metadata": {
        "id": "9ZxC6zxzAvBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your EDA Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}